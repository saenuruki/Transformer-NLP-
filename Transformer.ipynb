{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZpLJWFwk0ES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 基本的なAttention\n",
        "\n",
        "Attention の基本は query と memory(key, value) です。\n",
        "Attention とは query によって memory から必要な情報を選択的に引っ張ってくることです。\n",
        "memory から情報を引っ張ってくるときには、 query は key によって取得する memory を決定し、対応する value を取得します。\n",
        "\n",
        "まずは基本的な Attention として下記のようなネットワークを作ってみましょう。\n",
        "丸は Tensor, 四角はレイヤーもしくは処理を表しています。"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6AQ3iWXldAP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "728217b7-fe58-46e2-859d-d35035a65c2e"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr0Gf4jxlYjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicAttention(tf.keras.models.Model):\n",
        "  \n",
        "  def __init__(self, depth: int, *args, **kwargs):\n",
        "\n",
        "    super().__init__(*args, **kwargs)\n",
        "    self.depth = depth\n",
        "    self.query_dense_layer = tf.leras.layers.Dense(depth, use_bias=False, name='query_dense_layer')\n",
        "    self.key_dense_layer = tf.keras.layers.Dense(depth, use_bias=False, name='key_dense_layer')\n",
        "    self.value_dense_layer = tf.keras.layers.Dense(depth, use_bias=Fase, name='value_dense_layer')\n",
        "    self.output_dense_layer = tf.keras.layers.Dense(depth, use_bias=False, name='output_dense_layer')\n",
        "\n",
        "  def call(self, input: tf.Tensor, memory: tf.Tensor) -> tf.Tensor:\n",
        "\n",
        "    '''\n",
        "    input: queryの行列\n",
        "    memory: memoryの行列\n",
        "    '''\n",
        "\n",
        "    query = self.query_dense_layer(input) # [batch_size, query_length, depth]\n",
        "    key = self.key_dense_layer(memory) # [batch_size, memory_lenght, depth]\n",
        "    value = self.value_dense_layer(memory)\n",
        "\n",
        "    logit = tf.matmul(q, k, transpose_b=True) # queryとkeyの内積 -> queryとkeyの関連度を計算\n",
        "    attention_weight = tf.nn.softmax(logit, name='attention_weight') # softmaxで正則化\n",
        "    attention_output = tf.matmul(attention_weight, value) # 重みに従ってvalueから情報を索引\n",
        "    return self.output_dense_layer(attention_output)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}